# 덕질의 끝을 보여주고 싶은 Vlive [#](https://deview.kr/data/deview/2019/presentation/[242]덕질의+끝+V+LIVE_2(합본).pdf)
실시간성
* 실시간 메시지
  * 시스템 구조
    * 방송 시작 시 알림
      * As Is: Batch 방식의 서버
        * 100만 ~ 200만의 수신자의 경우 1분 이내로 처리
        * 1000만 ~ 의 경우 5 ~ 10분 소요
      * To Be: RabbitMQ - Worker Pool
    * 중복 수신자 처리
      * As Is: 중복 제거 작업을 발송 전에 진행
      * To Be: 실행 중에 실행
  * 1000만명 / 10분에서
  * 1600만명 / 30초로
  * 첫 알림 발송 - 방송 시작 = 0
* 송출/재생 Latency 최소화
* 장애 고립화

글로벌
* 송출 타입 최적화
  * 메인 라인과 백업 라인을 준비
  * 메인 라인 불량 시 백업 라인 사용
  * 사우디에서는 위성을 사용했었음
    * 위성은 날씨에 영향 받음
    * 위성 백업망과 TVU 백업망을 사용
* Global POP 활용
  * 지역 캐시 서버 활용
* 현지 테스트

트래픽
* 현황 파악
  * elastic 사용
    * 근데 얘가 느림
    * 큐 적용
* 다중 캐시
  * 1차: G-POP
  * 2차: EHCACHE
  * 3차: 메인 캐시
  * 최종: RDBMS
* CDN Routing Path 최적화
  * 공용 네트워크 구간 과부하로 품질 저하 가능성
    * 우회 경로 마련
* 스로틀링
  * API 호출 횟수 제한
  
